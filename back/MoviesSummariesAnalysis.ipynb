{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "oJuW15uZr3Or"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"movies_with_summary.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "true_sentiment_df = pd.read_csv('moviesWithSentiments.csv', usecols=['true_sentiment'])\n",
        "\n",
        "df['true_sentiment'] = true_sentiment_df['true_sentiment']"
      ],
      "metadata": {
        "id": "fLBRLeEXxMHG"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5A-0f-lr3Ox",
        "outputId": "793d4092-65a9-460b-c8e8-6c704244eefd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values:\n",
            "Title                0\n",
            "Year                 0\n",
            "Summary              5\n",
            "Short Summary        1\n",
            "Runtime              0\n",
            "Rating               0\n",
            "Movie Poster         0\n",
            "true_sentiment    3838\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values\n",
        "missing_values = df.isnull().sum()\n",
        "print(\"Missing Values:\")\n",
        "print(missing_values)\n",
        "\n",
        "# Drop rows with missing values in specific columns\n",
        "df.dropna(subset=['Summary'], inplace=True)\n",
        "df.dropna(subset=['Short Summary'], inplace=True)\n",
        "\n",
        "# Drop duplicates (if needed)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "df = df[df['Runtime'] > 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qSThV12r3O0",
        "outputId": "77074896-ba3a-46e8-a03b-dbf49d8a9dea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Dataset:\n",
            "                                               Title  Year  \\\n",
            "0                        Patton Oswalt: Annihilation  2017   \n",
            "1                                      New York Doll  2005   \n",
            "2  Mickey's Magical Christmas: Snowed in at the H...  2001   \n",
            "4                                      And Then I Go  2017   \n",
            "5                           An Extremely Goofy Movie  2000   \n",
            "\n",
            "                                             Summary  \\\n",
            "0  Patton Oswald, despite a personal tragedy, pro...   \n",
            "1  A recovering alcoholic and recently converted ...   \n",
            "2  After everyone is snowed in at the House of Mo...   \n",
            "4  In the cruel world of junior high, Edwin suffe...   \n",
            "5  It's a big time in Max's life. He's college bo...   \n",
            "\n",
            "                                       Short Summary  Runtime  Rating  \\\n",
            "0  Patton Oswalt, despite a personal tragedy, pro...       66     7.4   \n",
            "1  A recovering alcoholic and recently converted ...       75     7.9   \n",
            "2  Mickey and all his friends hold their own Chri...       65     6.8   \n",
            "4  In the cruel world of junior high, Edwin suffe...       99     7.6   \n",
            "5  Max goes to college, but to his embarassment h...       79     6.4   \n",
            "\n",
            "                                        Movie Poster true_sentiment  \n",
            "0  https://hydramovies.com/wp-content/uploads/201...          happy  \n",
            "1  https://hydramovies.com/wp-content/uploads/201...            sad  \n",
            "2  https://hydramovies.com/wp-content/uploads/201...          happy  \n",
            "4  https://hydramovies.com/wp-content/uploads/201...            sad  \n",
            "5  https://hydramovies.com/wp-content/uploads/201...          happy  \n"
          ]
        }
      ],
      "source": [
        "# Display the cleaned dataset\n",
        "print(\"Cleaned Dataset:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TextBlob model:**"
      ],
      "metadata": {
        "id": "_zLr43ArA5GG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xVM4R2ir3O2",
        "outputId": "d009b738-c718-4e34-850e-89faf3fe187e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from textblob import TextBlob\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download the NLTK stopwords and POS tagging data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Define a list of neutral words and proper noun tags\n",
        "NEUTRAL_WORDS = set(stopwords.words('english'))\n",
        "PROPER_NOUN_TAGS = {'NNP', 'NNPS'}\n",
        "\n",
        "# Function to preprocess text and remove neutral words and proper nouns\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    # Tag the tokens with parts-of-speech\n",
        "    tagged_tokens = nltk.pos_tag(tokens)\n",
        "\n",
        "    # Remove neutral words and proper nouns\n",
        "    filtered_tokens = [word for word, tag in tagged_tokens if word.lower() not in NEUTRAL_WORDS and tag not in PROPER_NOUN_TAGS]\n",
        "\n",
        "    # Join the filtered tokens back into a single string\n",
        "    filtered_text = ' '.join(filtered_tokens)\n",
        "\n",
        "    return filtered_text\n",
        "\n",
        "df['filtered_tokens'] = df['Summary'].apply(preprocess_text)\n",
        "\n",
        "# Function to calculate sentiment polarity after preprocessing text\n",
        "def calculate_sentiment_polarity(text):\n",
        "    # Preprocess the text to remove neutral words and proper nouns\n",
        "    preprocessed_text = preprocess_text(text)\n",
        "\n",
        "    # Use TextBlob to calculate sentiment polarity\n",
        "    blob = TextBlob(preprocessed_text)\n",
        "    polarity = blob.sentiment.polarity\n",
        "\n",
        "    return polarity\n",
        "\n",
        "def classify_sentiment(polarity):\n",
        "    if polarity == 0:\n",
        "        return 'neutral'\n",
        "    elif polarity > 0:\n",
        "        return 'happy'\n",
        "    else:\n",
        "        return 'sad'\n",
        "\n",
        "df['sentiment_polarity_textblob'] = df['filtered_tokens'].apply(calculate_sentiment_polarity)\n",
        "\n",
        "# Apply sentiment classification to the evaluation movie summaries\n",
        "df['Predicted_Sentiment_TextBlob'] = df['sentiment_polarity_textblob'].apply(classify_sentiment)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJIxIMjCblSX",
        "outputId": "ffb69f4d-c535-410f-ee78-1d9eecc0812a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2067 1371 255\n"
          ]
        }
      ],
      "source": [
        "h = 0\n",
        "s = 0\n",
        "n = 0\n",
        "\n",
        "for sentiment in df['Predicted_Sentiment_TextBlob']:\n",
        "    if sentiment == 'happy':\n",
        "        h += 1\n",
        "    elif sentiment == 'sad':\n",
        "        s += 1\n",
        "    else:\n",
        "        n += 1\n",
        "\n",
        "print(h, s, n)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQxLrmTwnhbt"
      },
      "source": [
        "**Vader pretrained model:**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Download the NLTK stopwords data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the VADER sentiment analyzer\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "# Define a list of neutral words\n",
        "NEUTRAL_WORDS = set(stopwords.words('english'))\n",
        "\n",
        "# Function to preprocess text and remove neutral words\n",
        "def preprocess_text(text):\n",
        "    # Tokenize the text\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "\n",
        "    # Remove neutral words\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in NEUTRAL_WORDS]\n",
        "\n",
        "    # Join the filtered tokens back into a single string\n",
        "    filtered_text = ' '.join(filtered_tokens)\n",
        "\n",
        "    return filtered_text\n",
        "\n",
        "# Function to calculate sentiment polarity after preprocessing text\n",
        "def calculate_sentiment_polarity(text):\n",
        "    # Preprocess the text to remove neutral words\n",
        "    preprocessed_text = preprocess_text(text)\n",
        "\n",
        "    # Use VADER to calculate sentiment polarity\n",
        "    polarity_scores = sia.polarity_scores(preprocessed_text)\n",
        "\n",
        "    return polarity_scores['compound']\n",
        "\n",
        "def classify_sentiment(polarity):\n",
        "    if polarity == 0:\n",
        "        return 'neutral'\n",
        "    elif polarity > 0:\n",
        "        return 'happy'\n",
        "    else:\n",
        "        return 'sad'\n",
        "\n",
        "df['sentiment_polarity_vader'] = df['Summary'].apply(calculate_sentiment_polarity)\n",
        "\n",
        "# Apply sentiment classification to the evaluation movie summaries\n",
        "df['Predicted_Sentiment_Vader'] = df['sentiment_polarity_vader'].apply(classify_sentiment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeciFqSkw7LJ",
        "outputId": "7c9acc69-aa8b-4e9f-e47b-11a962994d62"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "h = 0\n",
        "s = 0\n",
        "n = 0\n",
        "\n",
        "for sentiment in df['Predicted_Sentiment_Vader']:\n",
        "    if sentiment == 'happy':\n",
        "        h += 1\n",
        "    elif sentiment == 'sad':\n",
        "        s += 1\n",
        "    else:\n",
        "        n += 1\n",
        "\n",
        "print(h, s, n)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRn3GCLJniZT",
        "outputId": "57abd6ed-0818-4c0d-afc0-798c070a3e0f"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1690 1886 117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BERT fined tuned model for sentiment analysis:**"
      ],
      "metadata": {
        "id": "slqN5IK2BFea"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import nltk\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load BERT model and tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"sbcBI/sentiment_analysis\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"sbcBI/sentiment_analysis\")\n",
        "\n",
        "# Define a list of neutral words\n",
        "NEUTRAL_WORDS = set(stopwords.words('english'))\n",
        "\n",
        "# Function to preprocess text and remove neutral words\n",
        "def preprocess_text(text):\n",
        "    # Remove neutral words\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    filtered_tokens = [word for word in tokens if word.lower() not in NEUTRAL_WORDS]\n",
        "    filtered_text = ' '.join(filtered_tokens)\n",
        "\n",
        "    return filtered_text\n",
        "\n",
        "# Iterate through each movie summary\n",
        "for index, row in df.iterrows():\n",
        "    summary = row['Summary']\n",
        "\n",
        "    # Preprocess the text to remove neutral words\n",
        "    preprocessed_text = preprocess_text(summary)\n",
        "\n",
        "    # Tokenize the preprocessed text\n",
        "    inputs = tokenizer(preprocessed_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Perform inference\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    # Get predicted sentiment\n",
        "    predicted_class = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "    # Map predicted class to sentiment label\n",
        "    sentiment_label = {0: 'happy', 1: 'sad', 2: 'neutral'}[predicted_class]\n",
        "\n",
        "    # Update dataframe with sentiment label\n",
        "    df.at[index, 'Predicted_Sentiment_BERT'] = sentiment_label\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TchJTt8gxieX",
        "outputId": "c1c68bc4-54c3-4a16-d247-4e0502c2844e"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "id": "_rZpTzjS0kcV",
        "outputId": "722ccf5e-59f3-4319-a2ff-9e4e0345cea8"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Title  Year  \\\n",
              "0                        Patton Oswalt: Annihilation  2017   \n",
              "1                                      New York Doll  2005   \n",
              "2  Mickey's Magical Christmas: Snowed in at the H...  2001   \n",
              "4                                      And Then I Go  2017   \n",
              "5                           An Extremely Goofy Movie  2000   \n",
              "\n",
              "                                             Summary  \\\n",
              "0  Patton Oswald, despite a personal tragedy, pro...   \n",
              "1  A recovering alcoholic and recently converted ...   \n",
              "2  After everyone is snowed in at the House of Mo...   \n",
              "4  In the cruel world of junior high, Edwin suffe...   \n",
              "5  It's a big time in Max's life. He's college bo...   \n",
              "\n",
              "                                       Short Summary  Runtime  Rating  \\\n",
              "0  Patton Oswalt, despite a personal tragedy, pro...       66     7.4   \n",
              "1  A recovering alcoholic and recently converted ...       75     7.9   \n",
              "2  Mickey and all his friends hold their own Chri...       65     6.8   \n",
              "4  In the cruel world of junior high, Edwin suffe...       99     7.6   \n",
              "5  Max goes to college, but to his embarassment h...       79     6.4   \n",
              "\n",
              "                                        Movie Poster true_sentiment  \\\n",
              "0  https://hydramovies.com/wp-content/uploads/201...          happy   \n",
              "1  https://hydramovies.com/wp-content/uploads/201...            sad   \n",
              "2  https://hydramovies.com/wp-content/uploads/201...          happy   \n",
              "4  https://hydramovies.com/wp-content/uploads/201...            sad   \n",
              "5  https://hydramovies.com/wp-content/uploads/201...          happy   \n",
              "\n",
              "                                     filtered_tokens  \\\n",
              "0  , despite personal tragedy , produces best sta...   \n",
              "1  recovering alcoholic recently converted , `` '...   \n",
              "2  everyone snowed , suggests throw party . Every...   \n",
              "4  cruel world junior high , suffers state anxiet...   \n",
              "5  's big time 's life . 's college bound friends...   \n",
              "\n",
              "   sentiment_polarity_textblob Predicted_Sentiment_TextBlob  \\\n",
              "0                       0.6250                        happy   \n",
              "1                      -0.1250                          sad   \n",
              "2                       0.6500                        happy   \n",
              "4                      -0.2550                          sad   \n",
              "5                       0.1375                        happy   \n",
              "\n",
              "   sentiment_polarity_vader Predicted_Sentiment_Vader Predicted_Sentiment_BERT  \n",
              "0                    0.9339                     happy                  neutral  \n",
              "1                   -0.5106                       sad                      sad  \n",
              "2                    0.8352                     happy                  neutral  \n",
              "4                   -0.9403                       sad                  neutral  \n",
              "5                    0.8316                     happy                    happy  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da13dba7-b5e5-4ab6-ac80-f8c2887f51c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Year</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Short Summary</th>\n",
              "      <th>Runtime</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Movie Poster</th>\n",
              "      <th>true_sentiment</th>\n",
              "      <th>filtered_tokens</th>\n",
              "      <th>sentiment_polarity_textblob</th>\n",
              "      <th>Predicted_Sentiment_TextBlob</th>\n",
              "      <th>sentiment_polarity_vader</th>\n",
              "      <th>Predicted_Sentiment_Vader</th>\n",
              "      <th>Predicted_Sentiment_BERT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Patton Oswalt: Annihilation</td>\n",
              "      <td>2017</td>\n",
              "      <td>Patton Oswald, despite a personal tragedy, pro...</td>\n",
              "      <td>Patton Oswalt, despite a personal tragedy, pro...</td>\n",
              "      <td>66</td>\n",
              "      <td>7.4</td>\n",
              "      <td>https://hydramovies.com/wp-content/uploads/201...</td>\n",
              "      <td>happy</td>\n",
              "      <td>, despite personal tragedy , produces best sta...</td>\n",
              "      <td>0.6250</td>\n",
              "      <td>happy</td>\n",
              "      <td>0.9339</td>\n",
              "      <td>happy</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>New York Doll</td>\n",
              "      <td>2005</td>\n",
              "      <td>A recovering alcoholic and recently converted ...</td>\n",
              "      <td>A recovering alcoholic and recently converted ...</td>\n",
              "      <td>75</td>\n",
              "      <td>7.9</td>\n",
              "      <td>https://hydramovies.com/wp-content/uploads/201...</td>\n",
              "      <td>sad</td>\n",
              "      <td>recovering alcoholic recently converted , `` '...</td>\n",
              "      <td>-0.1250</td>\n",
              "      <td>sad</td>\n",
              "      <td>-0.5106</td>\n",
              "      <td>sad</td>\n",
              "      <td>sad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mickey's Magical Christmas: Snowed in at the H...</td>\n",
              "      <td>2001</td>\n",
              "      <td>After everyone is snowed in at the House of Mo...</td>\n",
              "      <td>Mickey and all his friends hold their own Chri...</td>\n",
              "      <td>65</td>\n",
              "      <td>6.8</td>\n",
              "      <td>https://hydramovies.com/wp-content/uploads/201...</td>\n",
              "      <td>happy</td>\n",
              "      <td>everyone snowed , suggests throw party . Every...</td>\n",
              "      <td>0.6500</td>\n",
              "      <td>happy</td>\n",
              "      <td>0.8352</td>\n",
              "      <td>happy</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>And Then I Go</td>\n",
              "      <td>2017</td>\n",
              "      <td>In the cruel world of junior high, Edwin suffe...</td>\n",
              "      <td>In the cruel world of junior high, Edwin suffe...</td>\n",
              "      <td>99</td>\n",
              "      <td>7.6</td>\n",
              "      <td>https://hydramovies.com/wp-content/uploads/201...</td>\n",
              "      <td>sad</td>\n",
              "      <td>cruel world junior high , suffers state anxiet...</td>\n",
              "      <td>-0.2550</td>\n",
              "      <td>sad</td>\n",
              "      <td>-0.9403</td>\n",
              "      <td>sad</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>An Extremely Goofy Movie</td>\n",
              "      <td>2000</td>\n",
              "      <td>It's a big time in Max's life. He's college bo...</td>\n",
              "      <td>Max goes to college, but to his embarassment h...</td>\n",
              "      <td>79</td>\n",
              "      <td>6.4</td>\n",
              "      <td>https://hydramovies.com/wp-content/uploads/201...</td>\n",
              "      <td>happy</td>\n",
              "      <td>'s big time 's life . 's college bound friends...</td>\n",
              "      <td>0.1375</td>\n",
              "      <td>happy</td>\n",
              "      <td>0.8316</td>\n",
              "      <td>happy</td>\n",
              "      <td>happy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da13dba7-b5e5-4ab6-ac80-f8c2887f51c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-da13dba7-b5e5-4ab6-ac80-f8c2887f51c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-da13dba7-b5e5-4ab6-ac80-f8c2887f51c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4037fc99-d9e0-43db-a175-f2eeb6e47c5e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4037fc99-d9e0-43db-a175-f2eeb6e47c5e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4037fc99-d9e0-43db-a175-f2eeb6e47c5e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3693,\n  \"fields\": [\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3680,\n        \"samples\": [\n          \"Untraceable\",\n          \"The Boy Next Door\",\n          \"Camp X-Ray\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 2000,\n        \"max\": 2018,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          2017,\n          2007,\n          2014\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3693,\n        \"samples\": [\n          \"Outside a mountain town grappling with a series of abductions and murders, Paul (Antonio Banderas), a reclusive writer, struggles to start what he hopes will be a career-saving screenplay. After a tense encounter at a diner with a drifter named Jack (Jonathan Rhys Meyers), Paul offers Jack a place to stay-and soon the edgy, demanding Jack muscles his way into Paul's work and the two men begin a jagged game of one-upmanship that will bring at least one tale to an end.\",\n          \"Based on the true story of the rise and fall of poker legend Stu \\\"The Kid\\\" Ungar.\",\n          \"Kubo lives a quiet, normal life in a small shoreside village until a spirit from the past turns his life upside down by re-igniting an age-old vendetta. This causes all sorts of havoc as gods and monsters chase Kubo who, in order to survive, must locate a magical suit of armor once worn by his late father, a legendary Samurai warrior.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Short Summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3693,\n        \"samples\": [\n          \"Outside a mountain town grappling with a series of abductions and murders, Paul (Antonio Banderas), a reclusive writer, struggles to start what he hopes will be a career-saving screenplay. ...\",\n          \"Based on the true story of the rise and fall of poker legend Stu &quot;The Kid&quot; Ungar.\",\n          \"A young boy named Kubo must locate a magical suit of armour worn by his late father in order to defeat a vengeful spirit from the past.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Runtime\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 3,\n        \"max\": 338,\n        \"num_unique_values\": 144,\n        \"samples\": [\n          162,\n          105,\n          83\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8972850168297027,\n        \"min\": 1.7,\n        \"max\": 9.5,\n        \"num_unique_values\": 71,\n        \"samples\": [\n          7.8,\n          7.4,\n          4.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Movie Poster\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3685,\n        \"samples\": [\n          \"https://hydramovies.com/wp-content/uploads/2018/04/Jamesy-Boy-Movie-Poster.jpg\",\n          \"https://hydramovies.com/wp-content/uploads/2018/04/Alan-Partridge-Movie-Poster.jpg\",\n          \"https://hydramovies.com/wp-content/uploads/2018/05/Time-Changer-Movie-Poster.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"happy\",\n          \"sad\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"filtered_tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3693,\n        \"samples\": [\n          \"Outside mountain town grappling series abductions murders , ( ) , reclusive writer , struggles start hopes career-saving screenplay . tense encounter diner drifter named ( ) , offers place stay-and soon edgy , demanding muscles way 's work two men begin jagged game one-upmanship bring least one tale end .\",\n          \"Based true story rise fall poker legend `` '' Ungar .\",\n          \"lives quiet , normal life small shoreside village spirit past turns life upside re-igniting age-old vendetta . causes sorts havoc gods monsters chase , order survive , must locate magical suit armor worn late father , legendary warrior .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_polarity_textblob\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19991334888723183,\n        \"min\": -1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2255,\n        \"samples\": [\n          -0.23999999999999994,\n          0.06944444444444445,\n          0.028571428571428577\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted_Sentiment_TextBlob\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"happy\",\n          \"sad\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment_polarity_vader\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7093949274722009,\n        \"min\": -0.9949,\n        \"max\": 0.9922,\n        \"num_unique_values\": 1028,\n        \"samples\": [\n          -0.9796,\n          -0.9325,\n          0.9719\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted_Sentiment_Vader\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"happy\",\n          \"sad\",\n          \"neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Predicted_Sentiment_BERT\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"neutral\",\n          \"sad\",\n          \"happy\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the DataFrame to a CSV file\n",
        "df.to_csv('movies_with_predictions.csv', index=False)"
      ],
      "metadata": {
        "id": "tn6XUW5TinQ5"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Results evaluation:**"
      ],
      "metadata": {
        "id": "OsJ1bX_9BSXT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Assuming your DataFrame containing the predicted sentiments is called df_predicted\n",
        "# Extract the first 50 rows with no NaN values in the 'true_sentiment' column\n",
        "df_first_50 = df.dropna(subset=['true_sentiment']).head(50)\n",
        "\n",
        "# Extract ground truth labels and predicted labels\n",
        "ground_truth_labels = df_first_50['true_sentiment']\n",
        "predicted_labels_bert = df_first_50['Predicted_Sentiment_BERT']\n",
        "predicted_labels_vader = df_first_50['Predicted_Sentiment_Vader']\n",
        "predicted_labels_textblob = df_first_50['Predicted_Sentiment_TextBlob']\n",
        "\n",
        "# Convert sentiment labels to numerical format\n",
        "sentiment_label_mapping = {'happy': 0, 'sad': 1, 'neutral': 2}\n",
        "ground_truth_numerical = [sentiment_label_mapping[label] for label in ground_truth_labels]\n",
        "\n",
        "# Convert predicted labels to numerical format\n",
        "predicted_labels_bert_numerical = [sentiment_label_mapping[label] for label in predicted_labels_bert]\n",
        "predicted_labels_vader_numerical = [sentiment_label_mapping[label] for label in predicted_labels_vader]\n",
        "predicted_labels_textblob_numerical = [sentiment_label_mapping[label] for label in predicted_labels_textblob]\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy_bert = accuracy_score(ground_truth_numerical, predicted_labels_bert_numerical)\n",
        "accuracy_vader = accuracy_score(ground_truth_numerical, predicted_labels_vader_numerical)\n",
        "accuracy_textblob = accuracy_score(ground_truth_numerical, predicted_labels_textblob_numerical)\n",
        "\n",
        "# Generate confusion matrices\n",
        "conf_matrix_bert = confusion_matrix(ground_truth_numerical, predicted_labels_bert_numerical)\n",
        "conf_matrix_vader = confusion_matrix(ground_truth_numerical, predicted_labels_vader_numerical)\n",
        "conf_matrix_textblob = confusion_matrix(ground_truth_numerical, predicted_labels_textblob_numerical)\n",
        "\n",
        "# Generate classification reports\n",
        "classification_report_bert = classification_report(ground_truth_numerical, predicted_labels_bert_numerical, target_names=['happy', 'sad', 'neutral'])\n",
        "classification_report_vader = classification_report(ground_truth_numerical, predicted_labels_vader_numerical, target_names=['happy', 'sad', 'neutral'])\n",
        "classification_report_textblob = classification_report(ground_truth_numerical, predicted_labels_textblob_numerical, target_names=['happy', 'sad', 'neutral'])\n",
        "\n",
        "# Print or visualize the evaluation results\n",
        "print(\"BERT Accuracy:\", accuracy_bert)\n",
        "print(\"BERT Confusion Matrix:\\n\", conf_matrix_bert)\n",
        "print(\"BERT Classification Report:\\n\", classification_report_bert)\n",
        "\n",
        "print(\"VADER Accuracy:\", accuracy_vader)\n",
        "print(\"VADER Confusion Matrix:\\n\", conf_matrix_vader)\n",
        "print(\"VADER Classification Report:\\n\", classification_report_vader)\n",
        "\n",
        "print(\"TextBlob Accuracy:\", accuracy_textblob)\n",
        "print(\"TextBlob Confusion Matrix:\\n\", conf_matrix_textblob)\n",
        "print(\"TextBlob Classification Report:\\n\", classification_report_textblob)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mxXn6qUtaXM",
        "outputId": "e9a76aaa-f5dc-469d-a9e8-16aec9e64ba3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT Accuracy: 0.3409090909090909\n",
            "BERT Confusion Matrix:\n",
            " [[ 8  1  3]\n",
            " [ 7  1  6]\n",
            " [10  2  6]]\n",
            "BERT Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       happy       0.32      0.67      0.43        12\n",
            "         sad       0.25      0.07      0.11        14\n",
            "     neutral       0.40      0.33      0.36        18\n",
            "\n",
            "    accuracy                           0.34        44\n",
            "   macro avg       0.32      0.36      0.30        44\n",
            "weighted avg       0.33      0.34      0.30        44\n",
            "\n",
            "VADER Accuracy: 0.38636363636363635\n",
            "VADER Confusion Matrix:\n",
            " [[9 3 0]\n",
            " [6 7 1]\n",
            " [9 8 1]]\n",
            "VADER Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       happy       0.38      0.75      0.50        12\n",
            "         sad       0.39      0.50      0.44        14\n",
            "     neutral       0.50      0.06      0.10        18\n",
            "\n",
            "    accuracy                           0.39        44\n",
            "   macro avg       0.42      0.44      0.35        44\n",
            "weighted avg       0.43      0.39      0.32        44\n",
            "\n",
            "TextBlob Accuracy: 0.3409090909090909\n",
            "TextBlob Confusion Matrix:\n",
            " [[ 7  5  0]\n",
            " [ 7  6  1]\n",
            " [11  5  2]]\n",
            "TextBlob Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       happy       0.28      0.58      0.38        12\n",
            "         sad       0.38      0.43      0.40        14\n",
            "     neutral       0.67      0.11      0.19        18\n",
            "\n",
            "    accuracy                           0.34        44\n",
            "   macro avg       0.44      0.37      0.32        44\n",
            "weighted avg       0.47      0.34      0.31        44\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}