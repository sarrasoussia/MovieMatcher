{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"movies_with_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values:\n",
      "Title            0\n",
      "Year             0\n",
      "Summary          5\n",
      "Short Summary    1\n",
      "Runtime          0\n",
      "Rating           0\n",
      "Movie Poster     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Missing Values:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in specific columns \n",
    "df.dropna(subset=['Summary'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates (if needed)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Patton Oswald, despite a personal tragedy, produces his best standup yet. Focusing on the tribulations of the Trump era and life after the loss of a loved one, Patton Oswald continues his journey to contribute joy to the world.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text data (if needed)\n",
    "# Example:\n",
    "# Remove special characters, punctuation, and unwanted symbols from the 'summary' column\n",
    "# You can define a custom function for cleaning or use regular expressions\n",
    "# For example, to remove special characters and punctuation:\n",
    "df['Summary'] = df['Summary'].str.replace('[^\\w\\s]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize text (if needed)\n",
    "# Convert text to lowercase\n",
    "# Example:\n",
    "df['Summary'] = df['Summary'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'patton oswald, despite a personal tragedy, produces his best standup yet. focusing on the tribulations of the trump era and life after the loss of a loved one, patton oswald continues his journey to contribute joy to the world.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Summary'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the Year column\n",
    "# df['Year'] = df['Year'].str.replace(r'\\D', '')  # Remove non-numeric characters\n",
    "\n",
    "df['Short Summary'] = df['Short Summary'].str.strip().str.lower().str.replace(r'[^\\w\\s]', '').str.replace(r'\\s+', ' ')\n",
    "\n",
    "# df['Runtime'] = df['Runtime'].str.replace(r'\\D', '')  # Remove non-numeric characters\n",
    "# df['Runtime'] = df['Runtime'].astype(float)  # Convert to float type\n",
    "df = df[df['Runtime'] > 0]  # Keep only rows where runtime is greater than 0\n",
    "\n",
    "# Clean the Rating column\n",
    "# df['Rating'] = df['Rating'].str.strip().str.upper()  # Remove leading and trailing whitespaces, convert to uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Dataset:\n",
      "                                               Title  Year  \\\n",
      "0                        Patton Oswalt: Annihilation  2017   \n",
      "1                                      New York Doll  2005   \n",
      "2  Mickey's Magical Christmas: Snowed in at the H...  2001   \n",
      "4                                      And Then I Go  2017   \n",
      "5                           An Extremely Goofy Movie  2000   \n",
      "\n",
      "                                             Summary  \\\n",
      "0  patton oswald, despite a personal tragedy, pro...   \n",
      "1  a recovering alcoholic and recently converted ...   \n",
      "2  after everyone is snowed in at the house of mo...   \n",
      "4  in the cruel world of junior high, edwin suffe...   \n",
      "5  it's a big time in max's life. he's college bo...   \n",
      "\n",
      "                                       Short Summary  Runtime  Rating  \\\n",
      "0  patton oswalt, despite a personal tragedy, pro...     66.0     7.4   \n",
      "1  a recovering alcoholic and recently converted ...     75.0     7.9   \n",
      "2  mickey and all his friends hold their own chri...     65.0     6.8   \n",
      "4  in the cruel world of junior high, edwin suffe...     99.0     7.6   \n",
      "5  max goes to college, but to his embarassment h...     79.0     6.4   \n",
      "\n",
      "                                        Movie Poster  \\\n",
      "0  https://hydramovies.com/wp-content/uploads/201...   \n",
      "1  https://hydramovies.com/wp-content/uploads/201...   \n",
      "2  https://hydramovies.com/wp-content/uploads/201...   \n",
      "4  https://hydramovies.com/wp-content/uploads/201...   \n",
      "5  https://hydramovies.com/wp-content/uploads/201...   \n",
      "\n",
      "                                              tokens  sentiment_polarity  \\\n",
      "0  [patton, oswald, despite, a, personal, tragedy...            0.625000   \n",
      "1  [a, recovering, alcoholic, and, recently, conv...           -0.037879   \n",
      "2  [after, everyone, is, snowed, in, at, the, hou...            0.633333   \n",
      "4  [in, the, cruel, world, of, junior, high, edwi...           -0.226667   \n",
      "5  [it, s, a, big, time, in, max, s, life, he, s,...            0.136364   \n",
      "\n",
      "  sentiment  \n",
      "0     happy  \n",
      "1       sad  \n",
      "2     happy  \n",
      "4       sad  \n",
      "5     happy  \n"
     ]
    }
   ],
   "source": [
    "# Display the cleaned dataset\n",
    "print(\"Cleaned Dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['patton',\n",
       " 'oswald',\n",
       " 'despite',\n",
       " 'a',\n",
       " 'personal',\n",
       " 'tragedy',\n",
       " 'produces',\n",
       " 'his',\n",
       " 'best',\n",
       " 'standup',\n",
       " 'yet',\n",
       " 'focusing',\n",
       " 'on',\n",
       " 'the',\n",
       " 'tribulations',\n",
       " 'of',\n",
       " 'the',\n",
       " 'trump',\n",
       " 'era',\n",
       " 'and',\n",
       " 'life',\n",
       " 'after',\n",
       " 'the',\n",
       " 'loss',\n",
       " 'of',\n",
       " 'a',\n",
       " 'loved',\n",
       " 'one',\n",
       " 'patton',\n",
       " 'oswald',\n",
       " 'continues',\n",
       " 'his',\n",
       " 'journey',\n",
       " 'to',\n",
       " 'contribute',\n",
       " 'joy',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Function to tokenize text using regular expressions\n",
    "def tokenize(text):\n",
    "    # Define pattern to match words\n",
    "    pattern = r'\\b\\w+\\b'\n",
    "    \n",
    "    # Tokenize text using pattern\n",
    "    tokens = re.findall(pattern, text.lower())\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply tokenization to the 'Summary' column\n",
    "df['tokens'] = df['Summary'].apply(tokenize)\n",
    "\n",
    "# Display the DataFrame with tokenized text\n",
    "df['tokens'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Year</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Short Summary</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie Poster</th>\n",
       "      <th>tokens</th>\n",
       "      <th>sentiment_polarity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Patton Oswalt: Annihilation</td>\n",
       "      <td>2017</td>\n",
       "      <td>patton oswald, despite a personal tragedy, pro...</td>\n",
       "      <td>patton oswalt, despite a personal tragedy, pro...</td>\n",
       "      <td>66.0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>https://hydramovies.com/wp-content/uploads/201...</td>\n",
       "      <td>[patton, oswald, despite, a, personal, tragedy...</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York Doll</td>\n",
       "      <td>2005</td>\n",
       "      <td>a recovering alcoholic and recently converted ...</td>\n",
       "      <td>a recovering alcoholic and recently converted ...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>https://hydramovies.com/wp-content/uploads/201...</td>\n",
       "      <td>[a, recovering, alcoholic, and, recently, conv...</td>\n",
       "      <td>-0.037879</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mickey's Magical Christmas: Snowed in at the H...</td>\n",
       "      <td>2001</td>\n",
       "      <td>after everyone is snowed in at the house of mo...</td>\n",
       "      <td>mickey and all his friends hold their own chri...</td>\n",
       "      <td>65.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>https://hydramovies.com/wp-content/uploads/201...</td>\n",
       "      <td>[after, everyone, is, snowed, in, at, the, hou...</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And Then I Go</td>\n",
       "      <td>2017</td>\n",
       "      <td>in the cruel world of junior high, edwin suffe...</td>\n",
       "      <td>in the cruel world of junior high, edwin suffe...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>https://hydramovies.com/wp-content/uploads/201...</td>\n",
       "      <td>[in, the, cruel, world, of, junior, high, edwi...</td>\n",
       "      <td>-0.226667</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>An Extremely Goofy Movie</td>\n",
       "      <td>2000</td>\n",
       "      <td>it's a big time in max's life. he's college bo...</td>\n",
       "      <td>max goes to college, but to his embarassment h...</td>\n",
       "      <td>79.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>https://hydramovies.com/wp-content/uploads/201...</td>\n",
       "      <td>[it, s, a, big, time, in, max, s, life, he, s,...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  Year  \\\n",
       "0                        Patton Oswalt: Annihilation  2017   \n",
       "1                                      New York Doll  2005   \n",
       "2  Mickey's Magical Christmas: Snowed in at the H...  2001   \n",
       "4                                      And Then I Go  2017   \n",
       "5                           An Extremely Goofy Movie  2000   \n",
       "\n",
       "                                             Summary  \\\n",
       "0  patton oswald, despite a personal tragedy, pro...   \n",
       "1  a recovering alcoholic and recently converted ...   \n",
       "2  after everyone is snowed in at the house of mo...   \n",
       "4  in the cruel world of junior high, edwin suffe...   \n",
       "5  it's a big time in max's life. he's college bo...   \n",
       "\n",
       "                                       Short Summary  Runtime  Rating  \\\n",
       "0  patton oswalt, despite a personal tragedy, pro...     66.0     7.4   \n",
       "1  a recovering alcoholic and recently converted ...     75.0     7.9   \n",
       "2  mickey and all his friends hold their own chri...     65.0     6.8   \n",
       "4  in the cruel world of junior high, edwin suffe...     99.0     7.6   \n",
       "5  max goes to college, but to his embarassment h...     79.0     6.4   \n",
       "\n",
       "                                        Movie Poster  \\\n",
       "0  https://hydramovies.com/wp-content/uploads/201...   \n",
       "1  https://hydramovies.com/wp-content/uploads/201...   \n",
       "2  https://hydramovies.com/wp-content/uploads/201...   \n",
       "4  https://hydramovies.com/wp-content/uploads/201...   \n",
       "5  https://hydramovies.com/wp-content/uploads/201...   \n",
       "\n",
       "                                              tokens  sentiment_polarity  \\\n",
       "0  [patton, oswald, despite, a, personal, tragedy...            0.625000   \n",
       "1  [a, recovering, alcoholic, and, recently, conv...           -0.037879   \n",
       "2  [after, everyone, is, snowed, in, at, the, hou...            0.633333   \n",
       "4  [in, the, cruel, world, of, junior, high, edwi...           -0.226667   \n",
       "5  [it, s, a, big, time, in, max, s, life, he, s,...            0.136364   \n",
       "\n",
       "  sentiment  \n",
       "0     happy  \n",
       "1       sad  \n",
       "2     happy  \n",
       "4       sad  \n",
       "5     happy  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Function to calculate sentiment polarity\n",
    "def calculate_sentiment_polarity(tokens):\n",
    "    # Join tokens back into a single string\n",
    "    text = ' '.join(tokens)\n",
    "    \n",
    "    # Use TextBlob to calculate sentiment polarity\n",
    "    blob = TextBlob(text)\n",
    "    polarity = blob.sentiment.polarity\n",
    "    \n",
    "    return polarity\n",
    "\n",
    "# Apply sentiment analysis to the 'tokens' column\n",
    "df['sentiment_polarity'] = df['tokens'].apply(calculate_sentiment_polarity)\n",
    "\n",
    "# Categorize sentiment based on polarity\n",
    "def categorize_sentiment(polarity):\n",
    "    if polarity > 0:\n",
    "        return 'happy'\n",
    "    elif polarity < 0:\n",
    "        return 'sad'\n",
    "    else:\n",
    "        return 'neutral'\n",
    "\n",
    "# Apply sentiment categorization\n",
    "df['sentiment'] = df['sentiment_polarity'].apply(categorize_sentiment)\n",
    "\n",
    "# Display the dataset with sentiment analysis results\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have categorised movies into 3 main ones: happy, sad and neutral. This need to be more tuned for  the audience's taste so that they can easily match their mood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:148: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\admin\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Python311\\Lib\\site-packages\\transformers\\optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Epoch 1:   0%|          | 0/93 [00:00<?, ?batches/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "Epoch 1:   3%|â–Ž         | 3/93 [10:26<5:21:29, 214.33s/batches]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming you have tokenized movie summaries and corresponding emotion labels\n",
    "# tokenized_summaries: List of tokenized movie summaries\n",
    "# labels: List of emotion labels (e.g., happy, sad, fear, neutral, disgust, etc.)\n",
    "\n",
    "# Convert emotion labels to numerical labels\n",
    "label_map = {\"happy\": 0, \"sad\": 1, \"fear\": 2, \"surprise\": 3, \"disgust\": 4, \"neutral\": 5}\n",
    "df['Numerical_Label'] = df['sentiment'].map(label_map)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Load BERT tokenizer and convert summaries to input IDs\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_input_ids = tokenizer(train_df['Summary'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "val_input_ids = tokenizer(val_df['Summary'].tolist(), padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "# Create DataLoader for training and validation sets\n",
    "train_data = TensorDataset(train_input_ids.input_ids, torch.tensor(train_df['Numerical_Label'].tolist()))\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "val_data = TensorDataset(val_input_ids.input_ids, torch.tensor(val_df['Numerical_Label'].tolist()))\n",
    "val_dataloader = DataLoader(val_data, batch_size=32)\n",
    "\n",
    "# Load pre-trained BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=6)  # Update num_labels to 6\n",
    "\n",
    "# Fine-tune the BERT model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch + 1}', unit='batches'):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            inputs, labels = batch\n",
    "            outputs = model(inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    print(f\"Epoch {epoch + 1}: Train Loss: {avg_train_loss}, Val Loss: {avg_val_loss}\")\n",
    "\n",
    "\n",
    "# Perform inference using the fine-tuned model\n",
    "# Your code for inference goes here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
